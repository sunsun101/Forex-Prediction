{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf477d04-5c8c-4251-af59-984b09ea5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c8d8ed-4de7-4d6d-9a62-15225ba81086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/st122283/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c24ab34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5796/3266637844.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(\"dataset/dataset_eurousd.csv\",sep=None)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset/dataset_eurousd.csv\",sep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36cf3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'<DATE>': 'DATE', '<TIME>': 'TIME','<OPEN>':'OPEN', '<HIGH>':'HIGH', '<LOW>':'LOW', '<CLOSE>':'CLOSE', '<TICKVOL>':'TICKVOL', '<VOL>':'VOL', '<SPREAD>':'SPREAD'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2f08e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>SPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1.30961</td>\n",
       "      <td>1.30965</td>\n",
       "      <td>1.30662</td>\n",
       "      <td>1.30687</td>\n",
       "      <td>2151</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>1.30688</td>\n",
       "      <td>1.30861</td>\n",
       "      <td>1.30668</td>\n",
       "      <td>1.30847</td>\n",
       "      <td>1490</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>1.30848</td>\n",
       "      <td>1.30876</td>\n",
       "      <td>1.30441</td>\n",
       "      <td>1.30443</td>\n",
       "      <td>2226</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>1.30444</td>\n",
       "      <td>1.30524</td>\n",
       "      <td>1.30330</td>\n",
       "      <td>1.30508</td>\n",
       "      <td>2322</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>1.30509</td>\n",
       "      <td>1.30618</td>\n",
       "      <td>1.30504</td>\n",
       "      <td>1.30581</td>\n",
       "      <td>1379</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61997</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>1.08861</td>\n",
       "      <td>1.08881</td>\n",
       "      <td>1.08592</td>\n",
       "      <td>1.08638</td>\n",
       "      <td>3897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61998</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>1.08637</td>\n",
       "      <td>1.08660</td>\n",
       "      <td>1.08504</td>\n",
       "      <td>1.08531</td>\n",
       "      <td>4443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61999</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>1.08531</td>\n",
       "      <td>1.08581</td>\n",
       "      <td>1.08364</td>\n",
       "      <td>1.08399</td>\n",
       "      <td>6250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62000</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>1.08399</td>\n",
       "      <td>1.08804</td>\n",
       "      <td>1.08388</td>\n",
       "      <td>1.08727</td>\n",
       "      <td>6825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62001</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>1.08725</td>\n",
       "      <td>1.08815</td>\n",
       "      <td>1.08716</td>\n",
       "      <td>1.08757</td>\n",
       "      <td>2771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62002 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE      TIME     OPEN     HIGH      LOW    CLOSE  TICKVOL  VOL  \\\n",
       "0      2012.04.09  00:00:00  1.30961  1.30965  1.30662  1.30687     2151    0   \n",
       "1      2012.04.09  01:00:00  1.30688  1.30861  1.30668  1.30847     1490    0   \n",
       "2      2012.04.09  02:00:00  1.30848  1.30876  1.30441  1.30443     2226    0   \n",
       "3      2012.04.09  03:00:00  1.30444  1.30524  1.30330  1.30508     2322    0   \n",
       "4      2012.04.09  04:00:00  1.30509  1.30618  1.30504  1.30581     1379    0   \n",
       "...           ...       ...      ...      ...      ...      ...      ...  ...   \n",
       "61997  2022.04.08  14:00:00  1.08861  1.08881  1.08592  1.08638     3897    0   \n",
       "61998  2022.04.08  15:00:00  1.08637  1.08660  1.08504  1.08531     4443    0   \n",
       "61999  2022.04.08  16:00:00  1.08531  1.08581  1.08364  1.08399     6250    0   \n",
       "62000  2022.04.08  17:00:00  1.08399  1.08804  1.08388  1.08727     6825    0   \n",
       "62001  2022.04.08  18:00:00  1.08725  1.08815  1.08716  1.08757     2771    0   \n",
       "\n",
       "       SPREAD  \n",
       "0          13  \n",
       "1          12  \n",
       "2          12  \n",
       "3          13  \n",
       "4          12  \n",
       "...       ...  \n",
       "61997       0  \n",
       "61998       0  \n",
       "61999       0  \n",
       "62000       0  \n",
       "62001       0  \n",
       "\n",
       "[62002 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df92ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DATE'] = pd.to_datetime(data['DATE'], format='%Y-%m-%d')\n",
    "# add time index\n",
    "# data['time_idx'] = 0\n",
    "index_value = 0;\n",
    "counter = 0;\n",
    "\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index,'time_idx'] = index_value;\n",
    "    counter = counter + 1;\n",
    "    if(counter > 5):\n",
    "        index_value = index_value + 1;\n",
    "        counter = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b80fa648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "         ...  \n",
       "61997    10332\n",
       "61998    10333\n",
       "61999    10333\n",
       "62000    10333\n",
       "62001    10333\n",
       "Name: time_idx, Length: 62002, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['time_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2db329b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data['time_idx'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d98221a6-b3f1-45a8-a37e-c7f41e140763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>SPREAD</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>6.200200e+04</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.185940</td>\n",
       "      <td>1.186719</td>\n",
       "      <td>1.185184</td>\n",
       "      <td>1.185940</td>\n",
       "      <td>3358.609513</td>\n",
       "      <td>1.354876e+09</td>\n",
       "      <td>4.064385</td>\n",
       "      <td>5166.333344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090433</td>\n",
       "      <td>0.090415</td>\n",
       "      <td>0.090448</td>\n",
       "      <td>0.090431</td>\n",
       "      <td>2721.869574</td>\n",
       "      <td>3.574439e+09</td>\n",
       "      <td>3.800078</td>\n",
       "      <td>2983.096677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.035550</td>\n",
       "      <td>1.037000</td>\n",
       "      <td>1.032490</td>\n",
       "      <td>1.035560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.116670</td>\n",
       "      <td>1.117430</td>\n",
       "      <td>1.116000</td>\n",
       "      <td>1.116670</td>\n",
       "      <td>1404.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.163250</td>\n",
       "      <td>1.161770</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>2571.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.244650</td>\n",
       "      <td>1.245675</td>\n",
       "      <td>1.243805</td>\n",
       "      <td>1.244668</td>\n",
       "      <td>4444.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.396280</td>\n",
       "      <td>1.399320</td>\n",
       "      <td>1.394860</td>\n",
       "      <td>1.396290</td>\n",
       "      <td>37898.000000</td>\n",
       "      <td>3.295386e+10</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>10333.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               OPEN          HIGH           LOW         CLOSE       TICKVOL  \\\n",
       "count  62002.000000  62002.000000  62002.000000  62002.000000  62002.000000   \n",
       "mean       1.185940      1.186719      1.185184      1.185940   3358.609513   \n",
       "std        0.090433      0.090415      0.090448      0.090431   2721.869574   \n",
       "min        1.035550      1.037000      1.032490      1.035560      1.000000   \n",
       "25%        1.116670      1.117430      1.116000      1.116670   1404.000000   \n",
       "50%        1.162500      1.163250      1.161770      1.162500   2571.000000   \n",
       "75%        1.244650      1.245675      1.243805      1.244668   4444.000000   \n",
       "max        1.396280      1.399320      1.394860      1.396290  37898.000000   \n",
       "\n",
       "                VOL        SPREAD      time_idx  \n",
       "count  6.200200e+04  62002.000000  62002.000000  \n",
       "mean   1.354876e+09      4.064385   5166.333344  \n",
       "std    3.574439e+09      3.800078   2983.096677  \n",
       "min    0.000000e+00      0.000000      0.000000  \n",
       "25%    0.000000e+00      1.000000   2583.000000  \n",
       "50%    0.000000e+00      3.000000   5166.000000  \n",
       "75%    0.000000e+00      7.000000   7750.000000  \n",
       "max    3.295386e+10    122.000000  10333.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f6ccd19-5a87-4579-9db7-ed7cc91ad831",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Time difference between steps has been idenfied as larger than 1 - set allow_missing_timesteps=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m max_encoder_length \u001b[39m=\u001b[39m \u001b[39m24\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m training_cutoff \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mtime_idx\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m max_prediction_length\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=4'>5</a>\u001b[0m training \u001b[39m=\u001b[39m TimeSeriesDataSet(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=5'>6</a>\u001b[0m     data[\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mtime_idx \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m training_cutoff],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=6'>7</a>\u001b[0m     time_idx\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtime_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=7'>8</a>\u001b[0m     target\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCLOSE\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=8'>9</a>\u001b[0m     group_ids\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtime_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=9'>10</a>\u001b[0m     min_encoder_length\u001b[39m=\u001b[39;49mmax_encoder_length \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m \u001b[39m2\u001b[39;49m,  \u001b[39m# keep encoder length long (as it is in the validation set)\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=10'>11</a>\u001b[0m     max_encoder_length\u001b[39m=\u001b[39;49mmax_encoder_length,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=11'>12</a>\u001b[0m     min_prediction_length\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=12'>13</a>\u001b[0m     max_prediction_length\u001b[39m=\u001b[39;49mmax_prediction_length,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=13'>14</a>\u001b[0m     static_categoricals\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=14'>15</a>\u001b[0m     static_reals\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=15'>16</a>\u001b[0m     time_varying_known_categoricals\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=16'>17</a>\u001b[0m     variable_groups\u001b[39m=\u001b[39;49m{}, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=17'>18</a>\u001b[0m     time_varying_known_reals\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtime_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=18'>19</a>\u001b[0m     time_varying_unknown_categoricals\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=19'>20</a>\u001b[0m     time_varying_unknown_reals\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=20'>21</a>\u001b[0m     target_normalizer\u001b[39m=\u001b[39;49mGroupNormalizer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=21'>22</a>\u001b[0m         groups\u001b[39m=\u001b[39;49m[], transformation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msoftplus\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=22'>23</a>\u001b[0m     ),  \u001b[39m# use softplus and normalize by group\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=23'>24</a>\u001b[0m     add_relative_time_idx\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=24'>25</a>\u001b[0m     add_target_scales\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=25'>26</a>\u001b[0m     add_encoder_length\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=26'>27</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=28'>29</a>\u001b[0m \u001b[39m# create validation set (predict=True) which means to predict the last max_prediction_length points in time\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=29'>30</a>\u001b[0m \u001b[39m# for each series\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000004vscode-remote?line=30'>31</a>\u001b[0m validation \u001b[39m=\u001b[39m TimeSeriesDataSet\u001b[39m.\u001b[39mfrom_dataset(training, data, predict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, stop_randomization\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:439\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=435'>436</a>\u001b[0m     \u001b[39massert\u001b[39;00m target \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscalers, \u001b[39m\"\u001b[39m\u001b[39mTarget normalizer is separate and not in scalers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=437'>438</a>\u001b[0m \u001b[39m# create index\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=438'>439</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_index(data, predict_mode\u001b[39m=\u001b[39;49mpredict_mode)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=440'>441</a>\u001b[0m \u001b[39m# convert to torch tensor for high performance data loading later\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=441'>442</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_to_tensors(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1193\u001b[0m, in \u001b[0;36mTimeSeriesDataSet._construct_index\u001b[0;34m(self, data, predict_mode)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1189'>1190</a>\u001b[0m \u001b[39m# if there are missing timesteps, we cannot say directly what is the last timestep to include\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1190'>1191</a>\u001b[0m \u001b[39m# therefore we iterate until it is found\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1191'>1192</a>\u001b[0m \u001b[39mif\u001b[39;00m (df_index[\u001b[39m\"\u001b[39m\u001b[39mtime_diff_to_next\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39many():\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1192'>1193</a>\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1193'>1194</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_missing_timesteps\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1194'>1195</a>\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mTime difference between steps has been idenfied as larger than 1 - set allow_missing_timesteps=True\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1196'>1197</a>\u001b[0m df_index[\u001b[39m\"\u001b[39m\u001b[39mindex_end\u001b[39m\u001b[39m\"\u001b[39m], missing_sequences \u001b[39m=\u001b[39m _find_end_indices(\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1197'>1198</a>\u001b[0m     diffs\u001b[39m=\u001b[39mdf_index\u001b[39m.\u001b[39mtime_diff_to_next\u001b[39m.\u001b[39mto_numpy(),\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1198'>1199</a>\u001b[0m     max_lengths\u001b[39m=\u001b[39m(max_time \u001b[39m-\u001b[39m df_index\u001b[39m.\u001b[39mtime)\u001b[39m.\u001b[39mto_numpy() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1199'>1200</a>\u001b[0m     min_length\u001b[39m=\u001b[39mmin_sequence_length,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1200'>1201</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1201'>1202</a>\u001b[0m \u001b[39m# add duplicates but mostly with shorter sequence length for start of timeseries\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1202'>1203</a>\u001b[0m \u001b[39m# while the previous steps have ensured that we start a sequence on every time step, the missing_sequences\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py?line=1203'>1204</a>\u001b[0m \u001b[39m# ensure that there is a sequence that finishes on every timestep\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Time difference between steps has been idenfied as larger than 1 - set allow_missing_timesteps=True"
     ]
    }
   ],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"CLOSE\",\n",
    "    group_ids=[\"time_idx\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    variable_groups={}, \n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf58947-b051-4bbe-b9b8-398731ea00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdb642c-896c-4c6f-9a51-63277067525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e812ba-4adf-4744-b410-91307d3ef596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eced39-0fad-4f2d-8e27-c667a880350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=0,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9da0ff-ea27-466d-a088-bbec2d40dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c4c8f-2b1b-4036-b839-3c66ed2be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955463b-9d0d-4c39-b018-bb31aead2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e654b7-205a-4b5b-8f1a-e973ef7b757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876aad4-f02d-4605-8c14-463985fe7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd78a50-6ef9-42bd-850c-55f382dd8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b831fe-d4ec-4de2-afba-6b67fa3a7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        x, raw_predictions, idx=indices[idx], add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles)\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e3e14-f358-4946-9ed5-0ebc7a093ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609c820-a044-44d4-a309-ed0b9055acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"quantiles\",\n",
    ")v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3a379-cccb-4c9c-ae66-ecbb2a3f1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction, x = best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"raw\",\n",
    "    return_x=True,\n",
    ")\n",
    "best_tft.plot_prediction(x, raw_prediction, idx=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753f22c-c0ea-4548-9287-54f6b6080662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = data[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "last_data = data[lambda x: x.time_idx == x.time_idx.max()]\n",
    "decoder_data = pd.concat(\n",
    "    [last_data.assign(date=lambda x: x.date + pd.offsets.MonthBegin(i)) for i in range(1, max_prediction_length + 1)],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# add time index consistent with \"data\"\n",
    "decoder_data[\"time_idx\"] = decoder_data[\"date\"].dt.year * 12 + decoder_data[\"date\"].dt.month\n",
    "decoder_data[\"time_idx\"] += encoder_data[\"time_idx\"].max() + 1 - decoder_data[\"time_idx\"].min()\n",
    "\n",
    "# adjust additional time feature(s)\n",
    "decoder_data[\"month\"] = decoder_data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a45af-9b12-4f8b-ace4-6102afbe2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(new_x, new_raw_predictions, idx=idx, show_future_observed=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaac79c-82e7-4f8b-897c-63586a236e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12264cca-c85e-4873-bd49-d02c3aa28c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency = best_tft.predict_dependency(\n",
    "    val_dataloader.dataset, \"discount_in_percent\", np.linspace(0, 30, 30), show_progress_bar=True, mode=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4259d9-05a5-40e7-a41c-f33068ea2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting median and 25% and 75% percentile\n",
    "agg_dependency = dependency.groupby(\"discount_in_percent\").normalized_prediction.agg(\n",
    "    median=\"median\", q25=lambda x: x.quantile(0.25), q75=lambda x: x.quantile(0.75)\n",
    ")\n",
    "ax = agg_dependency.plot(y=\"median\")\n",
    "ax.fill_between(agg_dependency.index, agg_dependency.q25, agg_dependency.q75, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d49074-d5e0-4c56-8c11-4e11c91c5437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
