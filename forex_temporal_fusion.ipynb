{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf477d04-5c8c-4251-af59-984b09ea5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c8d8ed-4de7-4d6d-9a62-15225ba81086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/st122283/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c24ab34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/st122283/labs/Forex-Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24500/3447474724.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(\"dataset/dataset_eurousd.csv\",sep=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "data = pd.read_csv(\"dataset/dataset_eurousd.csv\",sep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36cf3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'<DATE>': 'DATE', '<TIME>': 'TIME','<OPEN>':'OPEN', '<HIGH>':'HIGH', '<LOW>':'LOW', '<CLOSE>':'CLOSE', '<TICKVOL>':'TICKVOL', '<VOL>':'VOL', '<SPREAD>':'SPREAD'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2f08e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>SPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1.30961</td>\n",
       "      <td>1.30965</td>\n",
       "      <td>1.30662</td>\n",
       "      <td>1.30687</td>\n",
       "      <td>2151</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>1.30688</td>\n",
       "      <td>1.30861</td>\n",
       "      <td>1.30668</td>\n",
       "      <td>1.30847</td>\n",
       "      <td>1490</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>1.30848</td>\n",
       "      <td>1.30876</td>\n",
       "      <td>1.30441</td>\n",
       "      <td>1.30443</td>\n",
       "      <td>2226</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>1.30444</td>\n",
       "      <td>1.30524</td>\n",
       "      <td>1.30330</td>\n",
       "      <td>1.30508</td>\n",
       "      <td>2322</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>1.30509</td>\n",
       "      <td>1.30618</td>\n",
       "      <td>1.30504</td>\n",
       "      <td>1.30581</td>\n",
       "      <td>1379</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61997</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>1.08861</td>\n",
       "      <td>1.08881</td>\n",
       "      <td>1.08592</td>\n",
       "      <td>1.08638</td>\n",
       "      <td>3897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61998</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>1.08637</td>\n",
       "      <td>1.08660</td>\n",
       "      <td>1.08504</td>\n",
       "      <td>1.08531</td>\n",
       "      <td>4443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61999</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>1.08531</td>\n",
       "      <td>1.08581</td>\n",
       "      <td>1.08364</td>\n",
       "      <td>1.08399</td>\n",
       "      <td>6250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62000</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>1.08399</td>\n",
       "      <td>1.08804</td>\n",
       "      <td>1.08388</td>\n",
       "      <td>1.08727</td>\n",
       "      <td>6825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62001</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>1.08725</td>\n",
       "      <td>1.08815</td>\n",
       "      <td>1.08716</td>\n",
       "      <td>1.08757</td>\n",
       "      <td>2771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62002 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE      TIME     OPEN     HIGH      LOW    CLOSE  TICKVOL  VOL  \\\n",
       "0      2012.04.09  00:00:00  1.30961  1.30965  1.30662  1.30687     2151    0   \n",
       "1      2012.04.09  01:00:00  1.30688  1.30861  1.30668  1.30847     1490    0   \n",
       "2      2012.04.09  02:00:00  1.30848  1.30876  1.30441  1.30443     2226    0   \n",
       "3      2012.04.09  03:00:00  1.30444  1.30524  1.30330  1.30508     2322    0   \n",
       "4      2012.04.09  04:00:00  1.30509  1.30618  1.30504  1.30581     1379    0   \n",
       "...           ...       ...      ...      ...      ...      ...      ...  ...   \n",
       "61997  2022.04.08  14:00:00  1.08861  1.08881  1.08592  1.08638     3897    0   \n",
       "61998  2022.04.08  15:00:00  1.08637  1.08660  1.08504  1.08531     4443    0   \n",
       "61999  2022.04.08  16:00:00  1.08531  1.08581  1.08364  1.08399     6250    0   \n",
       "62000  2022.04.08  17:00:00  1.08399  1.08804  1.08388  1.08727     6825    0   \n",
       "62001  2022.04.08  18:00:00  1.08725  1.08815  1.08716  1.08757     2771    0   \n",
       "\n",
       "       SPREAD  \n",
       "0          13  \n",
       "1          12  \n",
       "2          12  \n",
       "3          13  \n",
       "4          12  \n",
       "...       ...  \n",
       "61997       0  \n",
       "61998       0  \n",
       "61999       0  \n",
       "62000       0  \n",
       "62001       0  \n",
       "\n",
       "[62002 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df92ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DATE'] = pd.to_datetime(data['DATE'], format='%Y-%m-%d')\n",
    "# add time index\n",
    "# data['time_idx'] = 0\n",
    "index_value = 0;\n",
    "counter = 0;\n",
    "\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index,'time_idx'] = index_value;\n",
    "    counter = counter + 1;\n",
    "    if(counter > 5):\n",
    "        index_value = index_value + 1;\n",
    "        counter = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80fa648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0.0\n",
       "1            0.0\n",
       "2            0.0\n",
       "3            0.0\n",
       "4            0.0\n",
       "          ...   \n",
       "61997    10332.0\n",
       "61998    10333.0\n",
       "61999    10333.0\n",
       "62000    10333.0\n",
       "62001    10333.0\n",
       "Name: time_idx, Length: 62002, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['time_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db329b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data['time_idx'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98221a6-b3f1-45a8-a37e-c7f41e140763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>SPREAD</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>6.200200e+04</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.185940</td>\n",
       "      <td>1.186719</td>\n",
       "      <td>1.185184</td>\n",
       "      <td>1.185940</td>\n",
       "      <td>3358.609513</td>\n",
       "      <td>1.354876e+09</td>\n",
       "      <td>4.064385</td>\n",
       "      <td>5166.333344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090433</td>\n",
       "      <td>0.090415</td>\n",
       "      <td>0.090448</td>\n",
       "      <td>0.090431</td>\n",
       "      <td>2721.869574</td>\n",
       "      <td>3.574439e+09</td>\n",
       "      <td>3.800078</td>\n",
       "      <td>2983.096677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.035550</td>\n",
       "      <td>1.037000</td>\n",
       "      <td>1.032490</td>\n",
       "      <td>1.035560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.116670</td>\n",
       "      <td>1.117430</td>\n",
       "      <td>1.116000</td>\n",
       "      <td>1.116670</td>\n",
       "      <td>1404.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.163250</td>\n",
       "      <td>1.161770</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>2571.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.244650</td>\n",
       "      <td>1.245675</td>\n",
       "      <td>1.243805</td>\n",
       "      <td>1.244668</td>\n",
       "      <td>4444.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.396280</td>\n",
       "      <td>1.399320</td>\n",
       "      <td>1.394860</td>\n",
       "      <td>1.396290</td>\n",
       "      <td>37898.000000</td>\n",
       "      <td>3.295386e+10</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>10333.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               OPEN          HIGH           LOW         CLOSE       TICKVOL  \\\n",
       "count  62002.000000  62002.000000  62002.000000  62002.000000  62002.000000   \n",
       "mean       1.185940      1.186719      1.185184      1.185940   3358.609513   \n",
       "std        0.090433      0.090415      0.090448      0.090431   2721.869574   \n",
       "min        1.035550      1.037000      1.032490      1.035560      1.000000   \n",
       "25%        1.116670      1.117430      1.116000      1.116670   1404.000000   \n",
       "50%        1.162500      1.163250      1.161770      1.162500   2571.000000   \n",
       "75%        1.244650      1.245675      1.243805      1.244668   4444.000000   \n",
       "max        1.396280      1.399320      1.394860      1.396290  37898.000000   \n",
       "\n",
       "                VOL        SPREAD      time_idx  \n",
       "count  6.200200e+04  62002.000000  62002.000000  \n",
       "mean   1.354876e+09      4.064385   5166.333344  \n",
       "std    3.574439e+09      3.800078   2983.096677  \n",
       "min    0.000000e+00      0.000000      0.000000  \n",
       "25%    0.000000e+00      1.000000   2583.000000  \n",
       "50%    0.000000e+00      3.000000   5166.000000  \n",
       "75%    0.000000e+00      7.000000   7750.000000  \n",
       "max    3.295386e+10    122.000000  10333.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c902c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time_idx'] = data['time_idx'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6ccd19-5a87-4579-9db7-ed7cc91ad831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1238: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 12006 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__VOL': 2000000}, {'__group_id__VOL': 3500000}, {'__group_id__VOL': 5500000}, {'__group_id__VOL': 6500000}, {'__group_id__VOL': 8000000}, {'__group_id__VOL': 14000000}, {'__group_id__VOL': 14500000}, {'__group_id__VOL': 18000000}, {'__group_id__VOL': 25000000}, {'__group_id__VOL': 31000000}]\n",
      "  warnings.warn(\n",
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1238: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 12006 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__VOL': 2000000}, {'__group_id__VOL': 3500000}, {'__group_id__VOL': 5500000}, {'__group_id__VOL': 6500000}, {'__group_id__VOL': 8000000}, {'__group_id__VOL': 14000000}, {'__group_id__VOL': 14500000}, {'__group_id__VOL': 18000000}, {'__group_id__VOL': 25000000}, {'__group_id__VOL': 31000000}]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"CLOSE\",\n",
    "    group_ids=[\"VOL\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    variable_groups={}, \n",
    "    time_varying_known_reals=[\"time_idx\", \"HIGH\", \"LOW\", \"OPEN\", \"TICKVOL\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"VOL\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=1)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cf58947-b051-4bbe-b9b8-398731ea00d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.000885009765625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdb642c-896c-4c6f-9a51-63277067525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 23.3k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e812ba-4adf-4744-b410-91307d3ef596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:42<00:00,  3.91it/s]Restoring states from the checkpoint path at /home/st122283/labs/Forex-Prediction/.lr_find_4f5b8d51-cef1-4f00-96f8-f2ae8f5574c7.ckpt\n",
      "/home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1718: UserWarning: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': None}\"].\n",
      "  rank_zero_warn(\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:43<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.5495408738576241\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6eced39-0fad-4f2d-8e27-c667a880350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 23.3k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=1,\n",
    "    devices=2, \n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd9da0ff-ea27-466d-a088-bbec2d40dc56",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=719'>720</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=720'>721</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=721'>722</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:809\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=805'>806</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=806'>807</a>\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=807'>808</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=808'>809</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=810'>811</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1215\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1213'>1214</a>\u001b[0m \u001b[39m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1214'>1215</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1216'>1217</a>\u001b[0m \u001b[39m# hook\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:71\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=69'>70</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, trainer: pl\u001b[39m.\u001b[39mTrainer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=70'>71</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_to_device()\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=71'>72</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msetup(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:68\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=66'>67</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_to_device\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=67'>68</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py:121\u001b[0m, in \u001b[0;36mDeviceDtypeModuleMixin.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=119'>120</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__update_properties(device\u001b[39m=\u001b[39mout[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39mout[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=120'>121</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=904'>905</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=906'>907</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m     module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchmetrics/metric.py:540\u001b[0m, in \u001b[0;36mMetric._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=538'>539</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor):\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=539'>540</a>\u001b[0m     this\u001b[39m.\u001b[39m_defaults[key] \u001b[39m=\u001b[39m fn(value)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=540'>541</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Sequence):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=902'>903</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=903'>904</a>\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=904'>905</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# fit network\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=2'>3</a>\u001b[0m     tft,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=3'>4</a>\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=4'>5</a>\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:768\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=748'>749</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=749'>750</a>\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=750'>751</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=764'>765</a>\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=765'>766</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=766'>767</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=767'>768</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=768'>769</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=769'>770</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:736\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=733'>734</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mreconciliate_processes(traceback\u001b[39m.\u001b[39mformat_exc())\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=734'>735</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_exception\u001b[39m\u001b[39m\"\u001b[39m, exception)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=735'>736</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_teardown()\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=736'>737</a>\u001b[0m \u001b[39m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=737'>738</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstage \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1298\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1294'>1295</a>\u001b[0m \u001b[39m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1295'>1296</a>\u001b[0m \u001b[39mCallback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1296'>1297</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_dispatch(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1297'>1298</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mteardown()\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1298'>1299</a>\u001b[0m loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_active_loop\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1299'>1300</a>\u001b[0m \u001b[39m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:98\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=95'>96</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=96'>97</a>\u001b[0m \u001b[39m# clean up memory\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=97'>98</a>\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mempty_cache()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py:114\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py?line=102'>103</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py?line=103'>104</a>\u001b[0m \u001b[39mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py?line=104'>105</a>\u001b[0m \u001b[39m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py?line=110'>111</a>\u001b[0m \u001b[39m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py?line=111'>112</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py?line=112'>113</a>\u001b[0m \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/cuda/memory.py?line=113'>114</a>\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_emptyCache()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c4c8f-2b1b-4036-b839-3c66ed2be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955463b-9d0d-4c39-b018-bb31aead2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e654b7-205a-4b5b-8f1a-e973ef7b757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876aad4-f02d-4605-8c14-463985fe7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd78a50-6ef9-42bd-850c-55f382dd8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b831fe-d4ec-4de2-afba-6b67fa3a7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        x, raw_predictions, idx=indices[idx], add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles)\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e3e14-f358-4946-9ed5-0ebc7a093ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609c820-a044-44d4-a309-ed0b9055acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"quantiles\",\n",
    ")v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3a379-cccb-4c9c-ae66-ecbb2a3f1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction, x = best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"raw\",\n",
    "    return_x=True,\n",
    ")\n",
    "best_tft.plot_prediction(x, raw_prediction, idx=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753f22c-c0ea-4548-9287-54f6b6080662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = data[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "last_data = data[lambda x: x.time_idx == x.time_idx.max()]\n",
    "decoder_data = pd.concat(\n",
    "    [last_data.assign(date=lambda x: x.date + pd.offsets.MonthBegin(i)) for i in range(1, max_prediction_length + 1)],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# add time index consistent with \"data\"\n",
    "decoder_data[\"time_idx\"] = decoder_data[\"date\"].dt.year * 12 + decoder_data[\"date\"].dt.month\n",
    "decoder_data[\"time_idx\"] += encoder_data[\"time_idx\"].max() + 1 - decoder_data[\"time_idx\"].min()\n",
    "\n",
    "# adjust additional time feature(s)\n",
    "decoder_data[\"month\"] = decoder_data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a45af-9b12-4f8b-ace4-6102afbe2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(new_x, new_raw_predictions, idx=idx, show_future_observed=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaac79c-82e7-4f8b-897c-63586a236e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12264cca-c85e-4873-bd49-d02c3aa28c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency = best_tft.predict_dependency(\n",
    "    val_dataloader.dataset, \"discount_in_percent\", np.linspace(0, 30, 30), show_progress_bar=True, mode=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4259d9-05a5-40e7-a41c-f33068ea2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting median and 25% and 75% percentile\n",
    "agg_dependency = dependency.groupby(\"discount_in_percent\").normalized_prediction.agg(\n",
    "    median=\"median\", q25=lambda x: x.quantile(0.25), q75=lambda x: x.quantile(0.75)\n",
    ")\n",
    "ax = agg_dependency.plot(y=\"median\")\n",
    "ax.fill_between(agg_dependency.index, agg_dependency.q25, agg_dependency.q75, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d49074-d5e0-4c56-8c11-4e11c91c5437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
