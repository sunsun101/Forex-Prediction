{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf477d04-5c8c-4251-af59-984b09ea5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59c8d8ed-4de7-4d6d-9a62-15225ba81086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c24ab34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/st122283/labs/Forex-Prediction\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/st122283/labs/Forex-Prediction')\n",
    "print(os.getcwd())\n",
    "data = pd.read_csv(\"dataset/dataset_eurousd.csv\",sep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36cf3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'<DATE>': 'DATE', '<TIME>': 'TIME','<OPEN>':'OPEN', '<HIGH>':'HIGH', '<LOW>':'LOW', '<CLOSE>':'CLOSE', '<TICKVOL>':'TICKVOL', '<VOL>':'VOL', '<SPREAD>':'SPREAD'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab2f08e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>SPREAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1.30961</td>\n",
       "      <td>1.30965</td>\n",
       "      <td>1.30662</td>\n",
       "      <td>1.30687</td>\n",
       "      <td>2151</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>1.30688</td>\n",
       "      <td>1.30861</td>\n",
       "      <td>1.30668</td>\n",
       "      <td>1.30847</td>\n",
       "      <td>1490</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>1.30848</td>\n",
       "      <td>1.30876</td>\n",
       "      <td>1.30441</td>\n",
       "      <td>1.30443</td>\n",
       "      <td>2226</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>03:00:00</td>\n",
       "      <td>1.30444</td>\n",
       "      <td>1.30524</td>\n",
       "      <td>1.30330</td>\n",
       "      <td>1.30508</td>\n",
       "      <td>2322</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.04.09</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>1.30509</td>\n",
       "      <td>1.30618</td>\n",
       "      <td>1.30504</td>\n",
       "      <td>1.30581</td>\n",
       "      <td>1379</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61997</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>1.08861</td>\n",
       "      <td>1.08881</td>\n",
       "      <td>1.08592</td>\n",
       "      <td>1.08638</td>\n",
       "      <td>3897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61998</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>1.08637</td>\n",
       "      <td>1.08660</td>\n",
       "      <td>1.08504</td>\n",
       "      <td>1.08531</td>\n",
       "      <td>4443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61999</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>1.08531</td>\n",
       "      <td>1.08581</td>\n",
       "      <td>1.08364</td>\n",
       "      <td>1.08399</td>\n",
       "      <td>6250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62000</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>1.08399</td>\n",
       "      <td>1.08804</td>\n",
       "      <td>1.08388</td>\n",
       "      <td>1.08727</td>\n",
       "      <td>6825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62001</th>\n",
       "      <td>2022.04.08</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>1.08725</td>\n",
       "      <td>1.08815</td>\n",
       "      <td>1.08716</td>\n",
       "      <td>1.08757</td>\n",
       "      <td>2771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62002 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE      TIME     OPEN     HIGH      LOW    CLOSE  TICKVOL  VOL  \\\n",
       "0      2012.04.09  00:00:00  1.30961  1.30965  1.30662  1.30687     2151    0   \n",
       "1      2012.04.09  01:00:00  1.30688  1.30861  1.30668  1.30847     1490    0   \n",
       "2      2012.04.09  02:00:00  1.30848  1.30876  1.30441  1.30443     2226    0   \n",
       "3      2012.04.09  03:00:00  1.30444  1.30524  1.30330  1.30508     2322    0   \n",
       "4      2012.04.09  04:00:00  1.30509  1.30618  1.30504  1.30581     1379    0   \n",
       "...           ...       ...      ...      ...      ...      ...      ...  ...   \n",
       "61997  2022.04.08  14:00:00  1.08861  1.08881  1.08592  1.08638     3897    0   \n",
       "61998  2022.04.08  15:00:00  1.08637  1.08660  1.08504  1.08531     4443    0   \n",
       "61999  2022.04.08  16:00:00  1.08531  1.08581  1.08364  1.08399     6250    0   \n",
       "62000  2022.04.08  17:00:00  1.08399  1.08804  1.08388  1.08727     6825    0   \n",
       "62001  2022.04.08  18:00:00  1.08725  1.08815  1.08716  1.08757     2771    0   \n",
       "\n",
       "       SPREAD  \n",
       "0          13  \n",
       "1          12  \n",
       "2          12  \n",
       "3          13  \n",
       "4          12  \n",
       "...       ...  \n",
       "61997       0  \n",
       "61998       0  \n",
       "61999       0  \n",
       "62000       0  \n",
       "62001       0  \n",
       "\n",
       "[62002 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df92ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DATE'] = pd.to_datetime(data['DATE'], format='%Y-%m-%d')\n",
    "# add time index\n",
    "# data['time_idx'] = 0\n",
    "index_value = 0;\n",
    "counter = 0;\n",
    "\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    data.loc[index,'time_idx'] = index_value;\n",
    "    counter = counter + 1;\n",
    "    if(counter > 5):\n",
    "        index_value = index_value + 1;\n",
    "        counter = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b80fa648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            0.0\n",
       "1            0.0\n",
       "2            0.0\n",
       "3            0.0\n",
       "4            0.0\n",
       "          ...   \n",
       "61997    10332.0\n",
       "61998    10333.0\n",
       "61999    10333.0\n",
       "62000    10333.0\n",
       "62001    10333.0\n",
       "Name: time_idx, Length: 62002, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['time_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2db329b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data['time_idx'] == 10333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d98221a6-b3f1-45a8-a37e-c7f41e140763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OPEN</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>LOW</th>\n",
       "      <th>CLOSE</th>\n",
       "      <th>TICKVOL</th>\n",
       "      <th>VOL</th>\n",
       "      <th>SPREAD</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>6.200200e+04</td>\n",
       "      <td>62002.000000</td>\n",
       "      <td>62002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.185940</td>\n",
       "      <td>1.186719</td>\n",
       "      <td>1.185184</td>\n",
       "      <td>1.185940</td>\n",
       "      <td>3358.609513</td>\n",
       "      <td>1.354876e+09</td>\n",
       "      <td>4.064385</td>\n",
       "      <td>5166.333344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090433</td>\n",
       "      <td>0.090415</td>\n",
       "      <td>0.090448</td>\n",
       "      <td>0.090431</td>\n",
       "      <td>2721.869574</td>\n",
       "      <td>3.574439e+09</td>\n",
       "      <td>3.800078</td>\n",
       "      <td>2983.096677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.035550</td>\n",
       "      <td>1.037000</td>\n",
       "      <td>1.032490</td>\n",
       "      <td>1.035560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.116670</td>\n",
       "      <td>1.117430</td>\n",
       "      <td>1.116000</td>\n",
       "      <td>1.116670</td>\n",
       "      <td>1404.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.162500</td>\n",
       "      <td>1.163250</td>\n",
       "      <td>1.161770</td>\n",
       "      <td>1.162500</td>\n",
       "      <td>2571.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.244650</td>\n",
       "      <td>1.245675</td>\n",
       "      <td>1.243805</td>\n",
       "      <td>1.244668</td>\n",
       "      <td>4444.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.396280</td>\n",
       "      <td>1.399320</td>\n",
       "      <td>1.394860</td>\n",
       "      <td>1.396290</td>\n",
       "      <td>37898.000000</td>\n",
       "      <td>3.295386e+10</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>10333.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               OPEN          HIGH           LOW         CLOSE       TICKVOL  \\\n",
       "count  62002.000000  62002.000000  62002.000000  62002.000000  62002.000000   \n",
       "mean       1.185940      1.186719      1.185184      1.185940   3358.609513   \n",
       "std        0.090433      0.090415      0.090448      0.090431   2721.869574   \n",
       "min        1.035550      1.037000      1.032490      1.035560      1.000000   \n",
       "25%        1.116670      1.117430      1.116000      1.116670   1404.000000   \n",
       "50%        1.162500      1.163250      1.161770      1.162500   2571.000000   \n",
       "75%        1.244650      1.245675      1.243805      1.244668   4444.000000   \n",
       "max        1.396280      1.399320      1.394860      1.396290  37898.000000   \n",
       "\n",
       "                VOL        SPREAD      time_idx  \n",
       "count  6.200200e+04  62002.000000  62002.000000  \n",
       "mean   1.354876e+09      4.064385   5166.333344  \n",
       "std    3.574439e+09      3.800078   2983.096677  \n",
       "min    0.000000e+00      0.000000      0.000000  \n",
       "25%    0.000000e+00      1.000000   2583.000000  \n",
       "50%    0.000000e+00      3.000000   5166.000000  \n",
       "75%    0.000000e+00      7.000000   7750.000000  \n",
       "max    3.295386e+10    122.000000  10333.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c902c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time_idx'] = data['time_idx'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "381099ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Currency'] = \"EURUSD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "648e4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.tail(61402).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38638d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "595    99\n",
       "596    99\n",
       "597    99\n",
       "598    99\n",
       "599    99\n",
       "Name: time_idx, Length: 600, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['time_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f6ccd19-5a87-4579-9db7-ed7cc91ad831",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"CLOSE\",\n",
    "    group_ids=[\"Currency\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    variable_groups={}, \n",
    "    time_varying_known_reals=[\"time_idx\", \"HIGH\", \"LOW\", \"OPEN\", \"TICKVOL\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"Currency\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=1)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cf58947-b051-4bbe-b9b8-398731ea00d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006983081693761051"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcdb642c-896c-4c6f-9a51-63277067525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 23.3k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    devices=2,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2e812ba-4adf-4744-b410-91307d3ef596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:27<00:00,  3.04it/s]Restoring states from the checkpoint path at /home/st122283/labs/Forex-Prediction/.lr_find_c8b08fba-f5ca-490b-9b37-94e9aca1d479.ckpt\n",
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:27<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 2.754228703338168\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6eced39-0fad-4f2d-8e27-c667a880350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 23.3k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=1,\n",
    "    devices=2,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd9da0ff-ea27-466d-a088-bbec2d40dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0     \n",
      "3  | prescalers                         | ModuleDict                      | 144   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.7 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 3.7 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.7 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "23.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.3 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/ScatterGatherKernel.cu:111: operator(): block: [0,0,0], thread: [0,0,0] Assertion `idx_dim >= 0 && idx_dim < index_size && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=719'>720</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=720'>721</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=721'>722</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:809\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=805'>806</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=806'>807</a>\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=807'>808</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=808'>809</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=810'>811</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1231'>1232</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1233'>1234</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1235'>1236</a>\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1321\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1319'>1320</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1320'>1321</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1343\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1341'>1342</a>\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1342'>1343</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1344'>1345</a>\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1411\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1409'>1410</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1410'>1411</a>\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1412'>1413</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:154\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=152'>153</a>\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=153'>154</a>\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=155'>156</a>\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=202'>203</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=203'>204</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/base.py?line=204'>205</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:127\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=125'>126</a>\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=126'>127</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=127'>128</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:222\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=220'>221</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=221'>222</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mvalidation_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=223'>224</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1763\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1761'>1762</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1762'>1763</a>\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1764'>1765</a>\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:344\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=342'>343</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=343'>344</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py:414\u001b[0m, in \u001b[0;36mBaseModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=412'>413</a>\u001b[0m log, out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(x, y, batch_idx)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=413'>414</a>\u001b[0m log\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_log(x, y, out, batch_idx))\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=414'>415</a>\u001b[0m \u001b[39mreturn\u001b[39;00m log\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:518\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.create_log\u001b[0;34m(self, x, y, out, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=516'>517</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_log\u001b[39m(\u001b[39mself\u001b[39m, x, y, out, batch_idx, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=517'>518</a>\u001b[0m     log \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate_log(x, y, out, batch_idx, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=518'>519</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_interval \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py:457\u001b[0m, in \u001b[0;36mBaseModel.create_log\u001b[0;34m(self, x, y, out, batch_idx, prediction_kwargs, quantiles_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=455'>456</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_interval \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=456'>457</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_prediction(\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=457'>458</a>\u001b[0m         x, out, batch_idx, prediction_kwargs\u001b[39m=\u001b[39;49mprediction_kwargs, quantiles_kwargs\u001b[39m=\u001b[39;49mquantiles_kwargs\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=458'>459</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=459'>460</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {}\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py:705\u001b[0m, in \u001b[0;36mBaseModel.log_prediction\u001b[0;34m(self, x, out, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=703'>704</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m log_indices:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=704'>705</a>\u001b[0m     fig \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplot_prediction(x, out, idx\u001b[39m=\u001b[39;49midx, add_loss_to_title\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/base_model.py?line=705'>706</a>\u001b[0m     tag \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_stage\u001b[39m}\u001b[39;00m\u001b[39m prediction\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:719\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.plot_prediction\u001b[0;34m(self, x, out, idx, plot_attention, add_loss_to_title, show_future_observed, ax, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=717'>718</a>\u001b[0m \u001b[39mif\u001b[39;00m plot_attention:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=718'>719</a>\u001b[0m     interpretation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpret_output(out\u001b[39m.\u001b[39;49miget(\u001b[39mslice\u001b[39;49m(idx, idx \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)))\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=719'>720</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m to_list(fig):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:629\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.interpret_output\u001b[0;34m(self, out, reduction, attention_prediction_horizon)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=627'>628</a>\u001b[0m encoder_length_histogram \u001b[39m=\u001b[39m integer_histogram(out[\u001b[39m\"\u001b[39m\u001b[39mencoder_lengths\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mmax_encoder_length)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=628'>629</a>\u001b[0m decoder_length_histogram \u001b[39m=\u001b[39m integer_histogram(\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=629'>630</a>\u001b[0m     out[\u001b[39m\"\u001b[39;49m\u001b[39mdecoder_lengths\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mmin\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mmax\u001b[39;49m\u001b[39m=\u001b[39;49mout[\u001b[39m\"\u001b[39;49m\u001b[39mdecoder_variables\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=630'>631</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py?line=632'>633</a>\u001b[0m \u001b[39m# mask where decoder and encoder where not applied when averaging variable selection weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py:29\u001b[0m, in \u001b[0;36minteger_histogram\u001b[0;34m(data, min, max)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py?line=17'>18</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py?line=18'>19</a>\u001b[0m \u001b[39mCreate histogram of integers in predefined range\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py?line=19'>20</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py?line=26'>27</a>\u001b[0m \u001b[39m    histogram\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py?line=27'>28</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py?line=28'>29</a>\u001b[0m uniques, counts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49munique(data, return_counts\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_forecasting/utils.py?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mmin\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py:422\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py?line=420'>421</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py?line=421'>422</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py:420\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py?line=418'>419</a>\u001b[0m \u001b[39mif\u001b[39;00m dispatch_flag:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py?line=419'>420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/_jit_internal.py?line=420'>421</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py:936\u001b[0m, in \u001b[0;36m_return_counts\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=933'>934</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _unique_impl(\u001b[39minput\u001b[39m, \u001b[39msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=935'>936</a>\u001b[0m output, _, counts \u001b[39m=\u001b[39m _unique_impl(\u001b[39minput\u001b[39;49m, \u001b[39msorted\u001b[39;49m, return_inverse, return_counts, dim)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=936'>937</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output, counts\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py:860\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=858'>859</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=859'>860</a>\u001b[0m     output, inverse_indices, counts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_unique2(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=860'>861</a>\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=861'>862</a>\u001b[0m         \u001b[39msorted\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39msorted\u001b[39;49m,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=862'>863</a>\u001b[0m         return_inverse\u001b[39m=\u001b[39;49mreturn_inverse,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=863'>864</a>\u001b[0m         return_counts\u001b[39m=\u001b[39;49mreturn_counts,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=864'>865</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/functional.py?line=865'>866</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# fit network\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=2'>3</a>\u001b[0m     tft,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=3'>4</a>\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=4'>5</a>\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/forex_temporal_fusion.ipynb#ch0000014vscode-remote?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:768\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=748'>749</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=749'>750</a>\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=750'>751</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=764'>765</a>\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=765'>766</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=766'>767</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=767'>768</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=768'>769</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=769'>770</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:736\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=733'>734</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mreconciliate_processes(traceback\u001b[39m.\u001b[39mformat_exc())\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=734'>735</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_exception\u001b[39m\u001b[39m\"\u001b[39m, exception)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=735'>736</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_teardown()\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=736'>737</a>\u001b[0m \u001b[39m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=737'>738</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstage \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1298\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1294'>1295</a>\u001b[0m \u001b[39m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1295'>1296</a>\u001b[0m \u001b[39mCallback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1296'>1297</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_dispatch(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1297'>1298</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mteardown()\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1298'>1299</a>\u001b[0m loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_active_loop\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1299'>1300</a>\u001b[0m \u001b[39m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:96\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=92'>93</a>\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mteardown()\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=93'>94</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_device\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=94'>95</a>\u001b[0m     \u001b[39m# GPU teardown\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=95'>96</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=96'>97</a>\u001b[0m     \u001b[39m# clean up memory\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py?line=97'>98</a>\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py:147\u001b[0m, in \u001b[0;36mDeviceDtypeModuleMixin.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=140'>141</a>\u001b[0m \u001b[39m\"\"\"Moves all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=141'>142</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=142'>143</a>\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=143'>144</a>\u001b[0m \u001b[39m    Module: self\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=144'>145</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=145'>146</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__update_properties(device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py?line=146'>147</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcpu()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:718\u001b[0m, in \u001b[0;36mModule.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=708'>709</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcpu\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=709'>710</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=710'>711</a>\u001b[0m \n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=711'>712</a>\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=715'>716</a>\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=716'>717</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=717'>718</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcpu())\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=575'>576</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=576'>577</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=577'>578</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=581'>582</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=582'>583</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=587'>588</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchmetrics/metric.py:540\u001b[0m, in \u001b[0;36mMetric._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=537'>538</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m this\u001b[39m.\u001b[39m_defaults\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=538'>539</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor):\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=539'>540</a>\u001b[0m         this\u001b[39m.\u001b[39m_defaults[key] \u001b[39m=\u001b[39m fn(value)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=540'>541</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Sequence):\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/torchmetrics/metric.py?line=541'>542</a>\u001b[0m         this\u001b[39m.\u001b[39m_defaults[key] \u001b[39m=\u001b[39m [fn(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m value]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:718\u001b[0m, in \u001b[0;36mModule.cpu.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=708'>709</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcpu\u001b[39m(\u001b[39mself\u001b[39m: T) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=709'>710</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=710'>711</a>\u001b[0m \n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=711'>712</a>\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=715'>716</a>\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=716'>717</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py?line=717'>718</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcpu())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c4c8f-2b1b-4036-b839-3c66ed2be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955463b-9d0d-4c39-b018-bb31aead2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e654b7-205a-4b5b-8f1a-e973ef7b757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876aad4-f02d-4605-8c14-463985fe7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd78a50-6ef9-42bd-850c-55f382dd8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b831fe-d4ec-4de2-afba-6b67fa3a7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        x, raw_predictions, idx=indices[idx], add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles)\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e3e14-f358-4946-9ed5-0ebc7a093ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609c820-a044-44d4-a309-ed0b9055acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"quantiles\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3a379-cccb-4c9c-ae66-ecbb2a3f1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction, x = best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"raw\",\n",
    "    return_x=True,\n",
    ")\n",
    "best_tft.plot_prediction(x, raw_prediction, idx=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753f22c-c0ea-4548-9287-54f6b6080662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = data[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "last_data = data[lambda x: x.time_idx == x.time_idx.max()]\n",
    "decoder_data = pd.concat(\n",
    "    [last_data.assign(date=lambda x: x.date + pd.offsets.MonthBegin(i)) for i in range(1, max_prediction_length + 1)],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# add time index consistent with \"data\"\n",
    "decoder_data[\"time_idx\"] = decoder_data[\"date\"].dt.year * 12 + decoder_data[\"date\"].dt.month\n",
    "decoder_data[\"time_idx\"] += encoder_data[\"time_idx\"].max() + 1 - decoder_data[\"time_idx\"].min()\n",
    "\n",
    "# adjust additional time feature(s)\n",
    "decoder_data[\"month\"] = decoder_data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a45af-9b12-4f8b-ace4-6102afbe2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(new_x, new_raw_predictions, idx=idx, show_future_observed=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaac79c-82e7-4f8b-897c-63586a236e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12264cca-c85e-4873-bd49-d02c3aa28c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency = best_tft.predict_dependency(\n",
    "    val_dataloader.dataset, \"discount_in_percent\", np.linspace(0, 30, 30), show_progress_bar=True, mode=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4259d9-05a5-40e7-a41c-f33068ea2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting median and 25% and 75% percentile\n",
    "agg_dependency = dependency.groupby(\"discount_in_percent\").normalized_prediction.agg(\n",
    "    median=\"median\", q25=lambda x: x.quantile(0.25), q75=lambda x: x.quantile(0.75)\n",
    ")\n",
    "ax = agg_dependency.plot(y=\"median\")\n",
    "ax.fill_between(agg_dependency.index, agg_dependency.q25, agg_dependency.q75, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d49074-d5e0-4c56-8c11-4e11c91c5437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
