{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf477d04-5c8c-4251-af59-984b09ea5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "os.chdir(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c8d8ed-4de7-4d6d-9a62-15225ba81086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e49e475-b0ab-48d9-a390-36e72f01f1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>...</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Agency_25</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1264.162234</td>\n",
       "      <td>1152.473405</td>\n",
       "      <td>111.688829</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.835008</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.678062</td>\n",
       "      <td>1225.306376</td>\n",
       "      <td>99.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Agency_29</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>8.7480</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>498567142</td>\n",
       "      <td>762225057</td>\n",
       "      <td>27.584615</td>\n",
       "      <td>1316.098485</td>\n",
       "      <td>1296.804924</td>\n",
       "      <td>19.293561</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>177</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168825</td>\n",
       "      <td>1634.434615</td>\n",
       "      <td>11.397086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>Agency_47</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>4.9680</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>454252482</td>\n",
       "      <td>789624076</td>\n",
       "      <td>30.665957</td>\n",
       "      <td>1269.250000</td>\n",
       "      <td>1266.490490</td>\n",
       "      <td>2.759510</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.217413</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1.603017</td>\n",
       "      <td>2625.472644</td>\n",
       "      <td>48.295650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Agency_53</td>\n",
       "      <td>SKU_07</td>\n",
       "      <td>21.6825</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>480693900</td>\n",
       "      <td>791658684</td>\n",
       "      <td>29.197727</td>\n",
       "      <td>1193.842373</td>\n",
       "      <td>1128.124395</td>\n",
       "      <td>65.717978</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>beer_capital</td>\n",
       "      <td>-</td>\n",
       "      <td>5.504745</td>\n",
       "      <td>240</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3.076505</td>\n",
       "      <td>38.529107</td>\n",
       "      <td>2511.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>Agency_17</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>960.5520</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>515468092</td>\n",
       "      <td>871204688</td>\n",
       "      <td>23.608120</td>\n",
       "      <td>1338.334248</td>\n",
       "      <td>1232.128069</td>\n",
       "      <td>106.206179</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>7.935699</td>\n",
       "      <td>259</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6.867508</td>\n",
       "      <td>2143.677462</td>\n",
       "      <td>396.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>1184.6535</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>425528909</td>\n",
       "      <td>734443953</td>\n",
       "      <td>28.668254</td>\n",
       "      <td>1369.556376</td>\n",
       "      <td>1161.135214</td>\n",
       "      <td>208.421162</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.218151</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7.077206</td>\n",
       "      <td>1566.643589</td>\n",
       "      <td>1881.866367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>5.5593</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>623319783</td>\n",
       "      <td>1049868815</td>\n",
       "      <td>31.915385</td>\n",
       "      <td>1922.486644</td>\n",
       "      <td>1651.307674</td>\n",
       "      <td>271.178970</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>14.105636</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1.715472</td>\n",
       "      <td>1385.225478</td>\n",
       "      <td>109.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>Agency_48</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>4275.1605</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>509281531</td>\n",
       "      <td>892192092</td>\n",
       "      <td>26.767857</td>\n",
       "      <td>1761.258209</td>\n",
       "      <td>1546.059670</td>\n",
       "      <td>215.198539</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>12.218455</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.360577</td>\n",
       "      <td>1757.950603</td>\n",
       "      <td>1925.272108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>Agency_07</td>\n",
       "      <td>SKU_21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>544203593</td>\n",
       "      <td>761469815</td>\n",
       "      <td>28.987755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2418.719550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12084</th>\n",
       "      <td>Agency_21</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>46.3608</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>589969396</td>\n",
       "      <td>940912941</td>\n",
       "      <td>32.478910</td>\n",
       "      <td>1675.922116</td>\n",
       "      <td>1413.571789</td>\n",
       "      <td>262.350327</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.654088</td>\n",
       "      <td>181</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3.836454</td>\n",
       "      <td>2034.293024</td>\n",
       "      <td>109.381800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          agency     sku     volume       date  industry_volume  soda_volume  \\\n",
       "291    Agency_25  SKU_03     0.5076 2013-01-01        492612703    718394219   \n",
       "871    Agency_29  SKU_02     8.7480 2015-01-01        498567142    762225057   \n",
       "19532  Agency_47  SKU_01     4.9680 2013-09-01        454252482    789624076   \n",
       "2089   Agency_53  SKU_07    21.6825 2013-10-01        480693900    791658684   \n",
       "9755   Agency_17  SKU_02   960.5520 2015-03-01        515468092    871204688   \n",
       "7561   Agency_05  SKU_03  1184.6535 2014-02-01        425528909    734443953   \n",
       "19204  Agency_11  SKU_05     5.5593 2017-08-01        623319783   1049868815   \n",
       "8781   Agency_48  SKU_04  4275.1605 2013-03-01        509281531    892192092   \n",
       "2540   Agency_07  SKU_21     0.0000 2015-10-01        544203593    761469815   \n",
       "12084  Agency_21  SKU_03    46.3608 2017-04-01        589969396    940912941   \n",
       "\n",
       "       avg_max_temp  price_regular  price_actual    discount  ...  \\\n",
       "291       25.845238    1264.162234   1152.473405  111.688829  ...   \n",
       "871       27.584615    1316.098485   1296.804924   19.293561  ...   \n",
       "19532     30.665957    1269.250000   1266.490490    2.759510  ...   \n",
       "2089      29.197727    1193.842373   1128.124395   65.717978  ...   \n",
       "9755      23.608120    1338.334248   1232.128069  106.206179  ...   \n",
       "7561      28.668254    1369.556376   1161.135214  208.421162  ...   \n",
       "19204     31.915385    1922.486644   1651.307674  271.178970  ...   \n",
       "8781      26.767857    1761.258209   1546.059670  215.198539  ...   \n",
       "2540      28.987755       0.000000      0.000000    0.000000  ...   \n",
       "12084     32.478910    1675.922116   1413.571789  262.350327  ...   \n",
       "\n",
       "       football_gold_cup  beer_capital  music_fest discount_in_percent  \\\n",
       "291                    -             -           -            8.835008   \n",
       "871                    -             -           -            1.465966   \n",
       "19532                  -             -           -            0.217413   \n",
       "2089                   -  beer_capital           -            5.504745   \n",
       "9755                   -             -  music_fest            7.935699   \n",
       "7561                   -             -           -           15.218151   \n",
       "19204                  -             -           -           14.105636   \n",
       "8781                   -             -  music_fest           12.218455   \n",
       "2540                   -             -           -            0.000000   \n",
       "12084                  -             -           -           15.654088   \n",
       "\n",
       "      timeseries time_idx month log_volume avg_volume_by_sku  \\\n",
       "291          228        0     1  -0.678062       1225.306376   \n",
       "871          177       24     1   2.168825       1634.434615   \n",
       "19532        322        8     9   1.603017       2625.472644   \n",
       "2089         240        9    10   3.076505         38.529107   \n",
       "9755         259       26     3   6.867508       2143.677462   \n",
       "7561          21       13     2   7.077206       1566.643589   \n",
       "19204         17       55     8   1.715472       1385.225478   \n",
       "8781         151        2     3   8.360577       1757.950603   \n",
       "2540         300       33    10 -18.420681          0.000000   \n",
       "12084        181       51     4   3.836454       2034.293024   \n",
       "\n",
       "      avg_volume_by_agency  \n",
       "291              99.650400  \n",
       "871              11.397086  \n",
       "19532            48.295650  \n",
       "2089           2511.035175  \n",
       "9755            396.022140  \n",
       "7561           1881.866367  \n",
       "19204           109.699200  \n",
       "8781           1925.272108  \n",
       "2540           2418.719550  \n",
       "12084           109.381800  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "data = get_stallion_data()\n",
    "\n",
    "# add time index\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()\n",
    "\n",
    "# add additional features\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_volume_by_sku\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume.transform(\"mean\")\n",
    "data[\"avg_volume_by_agency\"] = data.groupby([\"time_idx\", \"agency\"], observed=True).volume.transform(\"mean\")\n",
    "\n",
    "# we want to encode special days as one variable and thus need to first reverse one-hot encoding\n",
    "special_days = [\n",
    "    \"easter_day\",\n",
    "    \"good_friday\",\n",
    "    \"new_year\",\n",
    "    \"christmas\",\n",
    "    \"labor_day\",\n",
    "    \"independence_day\",\n",
    "    \"revolution_day_memorial\",\n",
    "    \"regional_games\",\n",
    "    \"fifa_u_17_world_cup\",\n",
    "    \"football_gold_cup\",\n",
    "    \"beer_capital\",\n",
    "    \"music_fest\",\n",
    "]\n",
    "data[special_days] = data[special_days].apply(lambda x: x.map({0: \"-\", 1: x.name})).astype(\"category\")\n",
    "data.sample(10, random_state=521)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd668b66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c360f001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24157"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[\"date\"].dt.year*12 + data[\"date\"].dt.month).min()\n",
    "\n",
    "# data[\"date\"].dt.month\n",
    "# data[\"date\"].dt.year * 12 + data[\"date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3faf7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agency\n",
      "sku\n",
      "volume\n",
      "date\n",
      "industry_volume\n",
      "soda_volume\n",
      "avg_max_temp\n",
      "price_regular\n",
      "price_actual\n",
      "discount\n",
      "avg_population_2017\n",
      "avg_yearly_household_income_2017\n",
      "easter_day\n",
      "good_friday\n",
      "new_year\n",
      "christmas\n",
      "labor_day\n",
      "independence_day\n",
      "revolution_day_memorial\n",
      "regional_games\n",
      "fifa_u_17_world_cup\n",
      "football_gold_cup\n",
      "beer_capital\n",
      "music_fest\n",
      "discount_in_percent\n",
      "timeseries\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = get_stallion_data()\n",
    "test\n",
    "for col in test.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98221a6-b3f1-45a8-a37e-c7f41e140763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>avg_population_2017</th>\n",
       "      <th>avg_yearly_household_income_2017</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21000.000000</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.00000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1492.403982</td>\n",
       "      <td>5.439214e+08</td>\n",
       "      <td>8.512000e+08</td>\n",
       "      <td>28.612404</td>\n",
       "      <td>1451.536344</td>\n",
       "      <td>1267.347450</td>\n",
       "      <td>184.374146</td>\n",
       "      <td>1.045065e+06</td>\n",
       "      <td>151073.494286</td>\n",
       "      <td>10.574884</td>\n",
       "      <td>174.50000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>2.464118</td>\n",
       "      <td>1492.403982</td>\n",
       "      <td>1492.403982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2711.496882</td>\n",
       "      <td>6.288022e+07</td>\n",
       "      <td>7.824340e+07</td>\n",
       "      <td>3.972833</td>\n",
       "      <td>683.362417</td>\n",
       "      <td>587.757323</td>\n",
       "      <td>257.469968</td>\n",
       "      <td>9.291926e+05</td>\n",
       "      <td>50409.593114</td>\n",
       "      <td>9.590813</td>\n",
       "      <td>101.03829</td>\n",
       "      <td>17.318515</td>\n",
       "      <td>8.178218</td>\n",
       "      <td>1051.790829</td>\n",
       "      <td>1328.239698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.130518e+08</td>\n",
       "      <td>6.964015e+08</td>\n",
       "      <td>16.731034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3121.690141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227100e+04</td>\n",
       "      <td>90240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.272388</td>\n",
       "      <td>5.090553e+08</td>\n",
       "      <td>7.890880e+08</td>\n",
       "      <td>25.374816</td>\n",
       "      <td>1311.547158</td>\n",
       "      <td>1178.365653</td>\n",
       "      <td>54.935108</td>\n",
       "      <td>6.018900e+04</td>\n",
       "      <td>110057.000000</td>\n",
       "      <td>3.749628</td>\n",
       "      <td>87.00000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>2.112923</td>\n",
       "      <td>932.285496</td>\n",
       "      <td>113.420250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>158.436000</td>\n",
       "      <td>5.512000e+08</td>\n",
       "      <td>8.649196e+08</td>\n",
       "      <td>28.479272</td>\n",
       "      <td>1495.174592</td>\n",
       "      <td>1324.695705</td>\n",
       "      <td>138.307225</td>\n",
       "      <td>1.232242e+06</td>\n",
       "      <td>131411.000000</td>\n",
       "      <td>8.948990</td>\n",
       "      <td>174.50000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>5.065351</td>\n",
       "      <td>1402.305264</td>\n",
       "      <td>1730.529771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1774.793475</td>\n",
       "      <td>5.893715e+08</td>\n",
       "      <td>9.005551e+08</td>\n",
       "      <td>31.568405</td>\n",
       "      <td>1725.652080</td>\n",
       "      <td>1517.311427</td>\n",
       "      <td>272.298630</td>\n",
       "      <td>1.729177e+06</td>\n",
       "      <td>206553.000000</td>\n",
       "      <td>15.647058</td>\n",
       "      <td>262.00000</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>7.481439</td>\n",
       "      <td>2195.362302</td>\n",
       "      <td>2595.316500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22526.610000</td>\n",
       "      <td>6.700157e+08</td>\n",
       "      <td>1.049869e+09</td>\n",
       "      <td>45.290476</td>\n",
       "      <td>19166.625000</td>\n",
       "      <td>4925.404000</td>\n",
       "      <td>19166.625000</td>\n",
       "      <td>3.137874e+06</td>\n",
       "      <td>247220.000000</td>\n",
       "      <td>226.740147</td>\n",
       "      <td>349.00000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>10.022453</td>\n",
       "      <td>4332.363750</td>\n",
       "      <td>5884.717375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             volume  industry_volume   soda_volume  avg_max_temp  \\\n",
       "count  21000.000000     2.100000e+04  2.100000e+04  21000.000000   \n",
       "mean    1492.403982     5.439214e+08  8.512000e+08     28.612404   \n",
       "std     2711.496882     6.288022e+07  7.824340e+07      3.972833   \n",
       "min        0.000000     4.130518e+08  6.964015e+08     16.731034   \n",
       "25%        8.272388     5.090553e+08  7.890880e+08     25.374816   \n",
       "50%      158.436000     5.512000e+08  8.649196e+08     28.479272   \n",
       "75%     1774.793475     5.893715e+08  9.005551e+08     31.568405   \n",
       "max    22526.610000     6.700157e+08  1.049869e+09     45.290476   \n",
       "\n",
       "       price_regular  price_actual      discount  avg_population_2017  \\\n",
       "count   21000.000000  21000.000000  21000.000000         2.100000e+04   \n",
       "mean     1451.536344   1267.347450    184.374146         1.045065e+06   \n",
       "std       683.362417    587.757323    257.469968         9.291926e+05   \n",
       "min         0.000000  -3121.690141      0.000000         1.227100e+04   \n",
       "25%      1311.547158   1178.365653     54.935108         6.018900e+04   \n",
       "50%      1495.174592   1324.695705    138.307225         1.232242e+06   \n",
       "75%      1725.652080   1517.311427    272.298630         1.729177e+06   \n",
       "max     19166.625000   4925.404000  19166.625000         3.137874e+06   \n",
       "\n",
       "       avg_yearly_household_income_2017  discount_in_percent   timeseries  \\\n",
       "count                      21000.000000         21000.000000  21000.00000   \n",
       "mean                      151073.494286            10.574884    174.50000   \n",
       "std                        50409.593114             9.590813    101.03829   \n",
       "min                        90240.000000             0.000000      0.00000   \n",
       "25%                       110057.000000             3.749628     87.00000   \n",
       "50%                       131411.000000             8.948990    174.50000   \n",
       "75%                       206553.000000            15.647058    262.00000   \n",
       "max                       247220.000000           226.740147    349.00000   \n",
       "\n",
       "           time_idx    log_volume  avg_volume_by_sku  avg_volume_by_agency  \n",
       "count  21000.000000  21000.000000       21000.000000          21000.000000  \n",
       "mean      29.500000      2.464118        1492.403982           1492.403982  \n",
       "std       17.318515      8.178218        1051.790829           1328.239698  \n",
       "min        0.000000    -18.420681           0.000000              0.000000  \n",
       "25%       14.750000      2.112923         932.285496            113.420250  \n",
       "50%       29.500000      5.065351        1402.305264           1730.529771  \n",
       "75%       44.250000      7.481439        2195.362302           2595.316500  \n",
       "max       59.000000     10.022453        4332.363750           5884.717375  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6ccd19-5a87-4579-9db7-ed7cc91ad831",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"agency\", \"sku\"],\n",
    "    static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"volume\",\n",
    "        \"log_volume\",\n",
    "        \"industry_volume\",\n",
    "        \"soda_volume\",\n",
    "        \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\",\n",
    "        \"avg_volume_by_sku\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf58947-b051-4bbe-b9b8-398731ea00d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293.0088195800781"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdb642c-896c-4c6f-9a51-63277067525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.7k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e812ba-4adf-4744-b410-91307d3ef596",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/.lr_find_d70cd18d-d526-4f88-ab8e-3b4452762d57.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# find optimal learning rate\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m res \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49mlr_find(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=2'>3</a>\u001b[0m     tft,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=3'>4</a>\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=4'>5</a>\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mval_dataloader,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=5'>6</a>\u001b[0m     max_lr\u001b[39m=\u001b[39;49m\u001b[39m10.0\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=6'>7</a>\u001b[0m     min_lr\u001b[39m=\u001b[39;49m\u001b[39m1e-6\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=7'>8</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msuggested learning rate: \u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m.\u001b[39msuggestion()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsunsun-lab/home/st122283/labs/Forex-Prediction/temporal_fusion.ipynb#ch0000009vscode-remote?line=10'>11</a>\u001b[0m fig \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mplot(show\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, suggest\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py:192\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=154'>155</a>\u001b[0m \u001b[39m\"\"\"Enables the user to do a range test of good initial learning rates, to reduce the amount of guesswork in\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=155'>156</a>\u001b[0m \u001b[39mpicking a good starting learning rate.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=156'>157</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=188'>189</a>\u001b[0m \u001b[39m        or if you are using more than one optimizer.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=189'>190</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=190'>191</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mauto_lr_find \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=191'>192</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtune(\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=192'>193</a>\u001b[0m     model,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=193'>194</a>\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mtrain_dataloaders,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=194'>195</a>\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mval_dataloaders,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=195'>196</a>\u001b[0m     datamodule\u001b[39m=\u001b[39;49mdatamodule,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=196'>197</a>\u001b[0m     lr_find_kwargs\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=197'>198</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmin_lr\u001b[39;49m\u001b[39m\"\u001b[39;49m: min_lr,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=198'>199</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmax_lr\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_lr,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=199'>200</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnum_training\u001b[39;49m\u001b[39m\"\u001b[39;49m: num_training,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=200'>201</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmode\u001b[39;49m\u001b[39m\"\u001b[39;49m: mode,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=201'>202</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mearly_stop_threshold\u001b[39;49m\u001b[39m\"\u001b[39;49m: early_stop_threshold,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=202'>203</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mupdate_attr\u001b[39;49m\u001b[39m\"\u001b[39;49m: update_attr,\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=203'>204</a>\u001b[0m     },\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=204'>205</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=205'>206</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mauto_lr_find \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=206'>207</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mlr_find\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1126\u001b[0m, in \u001b[0;36mTrainer.tune\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, scale_batch_size_kwargs, lr_find_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1120'>1121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1121'>1122</a>\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1122'>1123</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1124'>1125</a>\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1125'>1126</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49m_tune(\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1126'>1127</a>\u001b[0m         model, scale_batch_size_kwargs\u001b[39m=\u001b[39;49mscale_batch_size_kwargs, lr_find_kwargs\u001b[39m=\u001b[39;49mlr_find_kwargs\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1127'>1128</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1129'>1130</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=1130'>1131</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtuning \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py:63\u001b[0m, in \u001b[0;36mTuner._tune\u001b[0;34m(self, model, scale_batch_size_kwargs, lr_find_kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=60'>61</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mauto_lr_find:\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=61'>62</a>\u001b[0m     lr_find_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mupdate_attr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=62'>63</a>\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39mlr_find\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m lr_find(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer, model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mlr_find_kwargs)\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=64'>65</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mFINISHED\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/tuning.py?line=66'>67</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py:207\u001b[0m, in \u001b[0;36mlr_find\u001b[0;34m(trainer, model, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py?line=204'>205</a>\u001b[0m \u001b[39m# Save initial model, that is loaded after learning rate is found\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py?line=205'>206</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(trainer\u001b[39m.\u001b[39mdefault_root_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.lr_find_\u001b[39m\u001b[39m{\u001b[39;00muuid\u001b[39m.\u001b[39muuid4()\u001b[39m}\u001b[39;00m\u001b[39m.ckpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py?line=206'>207</a>\u001b[0m trainer\u001b[39m.\u001b[39;49msave_checkpoint(ckpt_path)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py?line=207'>208</a>\u001b[0m params \u001b[39m=\u001b[39m __lr_finder_dump_params(trainer)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py?line=209'>210</a>\u001b[0m \u001b[39m# Set to values that are required by the algorithm\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2450\u001b[0m, in \u001b[0;36mTrainer.save_checkpoint\u001b[0;34m(self, filepath, weights_only, storage_options)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2437'>2438</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_checkpoint\u001b[39m(\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2438'>2439</a>\u001b[0m     \u001b[39mself\u001b[39m, filepath: _PATH, weights_only: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, storage_options: Optional[Any] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2439'>2440</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2440'>2441</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2441'>2442</a>\u001b[0m \u001b[39m    Runs routine to create a checkpoint.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2442'>2443</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2447'>2448</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2448'>2449</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py?line=2449'>2450</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_checkpoint_connector\u001b[39m.\u001b[39;49msave_checkpoint(filepath, weights_only\u001b[39m=\u001b[39;49mweights_only, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:445\u001b[0m, in \u001b[0;36mCheckpointConnector.save_checkpoint\u001b[0;34m(self, filepath, weights_only, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py?line=436'>437</a>\u001b[0m \u001b[39m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py?line=437'>438</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py?line=438'>439</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py?line=441'>442</a>\u001b[0m \u001b[39m    storage_options: parameter for how to save to storage, passed to ``CheckpointIO`` plugin\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py?line=442'>443</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py?line=443'>444</a>\u001b[0m _checkpoint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdump_checkpoint(weights_only)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py?line=444'>445</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msave_checkpoint(_checkpoint, filepath, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:418\u001b[0m, in \u001b[0;36mStrategy.save_checkpoint\u001b[0;34m(self, checkpoint, filepath, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=409'>410</a>\u001b[0m \u001b[39m\"\"\"Save model/training states as a checkpoint file through state-dump and file-write.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=410'>411</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=411'>412</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=414'>415</a>\u001b[0m \u001b[39m    storage_options: parameter for how to save to storage, passed to ``CheckpointIO`` plugin\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=415'>416</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=416'>417</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_global_zero:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py?line=417'>418</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheckpoint_io\u001b[39m.\u001b[39;49msave_checkpoint(checkpoint, filepath, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py:54\u001b[0m, in \u001b[0;36mTorchCheckpointIO.save_checkpoint\u001b[0;34m(self, checkpoint, path, storage_options)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=50'>51</a>\u001b[0m fs\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=52'>53</a>\u001b[0m     \u001b[39m# write the checkpoint dictionary on the file\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=53'>54</a>\u001b[0m     atomic_save(checkpoint, path)\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=54'>55</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=55'>56</a>\u001b[0m     \u001b[39m# todo (sean): is this try catch necessary still?\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=56'>57</a>\u001b[0m     \u001b[39m# https://github.com/PyTorchLightning/pytorch-lightning/pull/431\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/plugins/io/torch_plugin.py?line=57'>58</a>\u001b[0m     key \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mLightningModule\u001b[39m.\u001b[39mCHECKPOINT_HYPER_PARAMS_KEY\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:68\u001b[0m, in \u001b[0;36matomic_save\u001b[0;34m(checkpoint, filepath)\u001b[0m\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py?line=65'>66</a>\u001b[0m bytesbuffer \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py?line=66'>67</a>\u001b[0m torch\u001b[39m.\u001b[39msave(checkpoint, bytesbuffer)\n\u001b[0;32m---> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py?line=67'>68</a>\u001b[0m \u001b[39mwith\u001b[39;00m fsspec\u001b[39m.\u001b[39mopen(filepath, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='file:///home/st122283/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py?line=68'>69</a>\u001b[0m     f\u001b[39m.\u001b[39mwrite(bytesbuffer\u001b[39m.\u001b[39mgetvalue())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fsspec/core.py:103\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/core.py?line=99'>100</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/core.py?line=100'>101</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/core.py?line=102'>103</a>\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/core.py?line=104'>105</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfobjects \u001b[39m=\u001b[39m [f]\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/core.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fsspec/spec.py:1009\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1006'>1007</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1007'>1008</a>\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1008'>1009</a>\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1009'>1010</a>\u001b[0m         path,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1010'>1011</a>\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1011'>1012</a>\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1012'>1013</a>\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1013'>1014</a>\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1014'>1015</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1015'>1016</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1016'>1017</a>\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/spec.py?line=1017'>1018</a>\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fsspec/implementations/local.py:155\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=152'>153</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=153'>154</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=154'>155</a>\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fsspec/implementations/local.py:250\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=247'>248</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=248'>249</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=249'>250</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fsspec/implementations/local.py:255\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=252'>253</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=253'>254</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=254'>255</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=255'>256</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    <a href='file:///home/st122283/.local/lib/python3.8/site-packages/fsspec/implementations/local.py?line=256'>257</a>\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/.lr_find_d70cd18d-d526-4f88-ab8e-3b4452762d57.ckpt'"
     ]
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eced39-0fad-4f2d-8e27-c667a880350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=0,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9da0ff-ea27-466d-a088-bbec2d40dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c4c8f-2b1b-4036-b839-3c66ed2be00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955463b-9d0d-4c39-b018-bb31aead2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e654b7-205a-4b5b-8f1a-e973ef7b757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876aad4-f02d-4605-8c14-463985fe7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd78a50-6ef9-42bd-850c-55f382dd8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b831fe-d4ec-4de2-afba-6b67fa3a7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        x, raw_predictions, idx=indices[idx], add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles)\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31e3e14-f358-4946-9ed5-0ebc7a093ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a609c820-a044-44d4-a309-ed0b9055acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"quantiles\",\n",
    ")v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3a379-cccb-4c9c-ae66-ecbb2a3f1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prediction, x = best_tft.predict(\n",
    "    training.filter(lambda x: (x.agency == \"Agency_01\") & (x.sku == \"SKU_01\") & (x.time_idx_first_prediction == 15)),\n",
    "    mode=\"raw\",\n",
    "    return_x=True,\n",
    ")\n",
    "best_tft.plot_prediction(x, raw_prediction, idx=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753f22c-c0ea-4548-9287-54f6b6080662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = data[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "last_data = data[lambda x: x.time_idx == x.time_idx.max()]\n",
    "decoder_data = pd.concat(\n",
    "    [last_data.assign(date=lambda x: x.date + pd.offsets.MonthBegin(i)) for i in range(1, max_prediction_length + 1)],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# add time index consistent with \"data\"\n",
    "decoder_data[\"time_idx\"] = decoder_data[\"date\"].dt.year * 12 + decoder_data[\"date\"].dt.month\n",
    "decoder_data[\"time_idx\"] += encoder_data[\"time_idx\"].max() + 1 - decoder_data[\"time_idx\"].min()\n",
    "\n",
    "# adjust additional time feature(s)\n",
    "decoder_data[\"month\"] = decoder_data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a45af-9b12-4f8b-ace4-6102afbe2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(new_x, new_raw_predictions, idx=idx, show_future_observed=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaac79c-82e7-4f8b-897c-63586a236e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12264cca-c85e-4873-bd49-d02c3aa28c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency = best_tft.predict_dependency(\n",
    "    val_dataloader.dataset, \"discount_in_percent\", np.linspace(0, 30, 30), show_progress_bar=True, mode=\"dataframe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4259d9-05a5-40e7-a41c-f33068ea2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting median and 25% and 75% percentile\n",
    "agg_dependency = dependency.groupby(\"discount_in_percent\").normalized_prediction.agg(\n",
    "    median=\"median\", q25=lambda x: x.quantile(0.25), q75=lambda x: x.quantile(0.75)\n",
    ")\n",
    "ax = agg_dependency.plot(y=\"median\")\n",
    "ax.fill_between(agg_dependency.index, agg_dependency.q25, agg_dependency.q75, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d49074-d5e0-4c56-8c11-4e11c91c5437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
